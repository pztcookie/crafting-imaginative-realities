{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02651f20f29047b78d3b386322295ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49802b163e74474c89dd9d1df08a4347",
              "IPY_MODEL_709769c8c13b4a0d8732566661fbbe31",
              "IPY_MODEL_e0d37eba4c4447cdb7b94adafe08746b"
            ],
            "layout": "IPY_MODEL_9cdde9d9c208478daa47ed660f487416"
          }
        },
        "49802b163e74474c89dd9d1df08a4347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94017d5ff0ae42ebb610b63d70522698",
            "placeholder": "​",
            "style": "IPY_MODEL_cd726dcba31948c891cfcf4bb362318d",
            "value": "open_clip_pytorch_model.bin: 100%"
          }
        },
        "709769c8c13b4a0d8732566661fbbe31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9640fe5678864b5ab8cf5798cecd1abd",
            "max": 3944692325,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ee0456a4f064d01a8cc7b4ecf553375",
            "value": 3944692325
          }
        },
        "e0d37eba4c4447cdb7b94adafe08746b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f650e84f22a144cea907a34152498273",
            "placeholder": "​",
            "style": "IPY_MODEL_4613cef43fe84a4ab1d36e9b6cfa8678",
            "value": " 3.94G/3.94G [01:05&lt;00:00, 50.0MB/s]"
          }
        },
        "9cdde9d9c208478daa47ed660f487416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94017d5ff0ae42ebb610b63d70522698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd726dcba31948c891cfcf4bb362318d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9640fe5678864b5ab8cf5798cecd1abd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee0456a4f064d01a8cc7b4ecf553375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f650e84f22a144cea907a34152498273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4613cef43fe84a4ab1d36e9b6cfa8678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR5wXpwRrLy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc301ac-fd72-4bad-bd91-fd253cc18b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install adapter-transformers\n",
        "!pip install torch\n",
        "!pip install datasets\n",
        "!pip install webdataset\n",
        "!pip install pytorch_lightning\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "# download the linear mse model path\n",
        "!wget https://github.com/microsoft/LMOps/raw/main/promptist/aesthetic/sac%2Blogos%2Bava1-l14-linearMSE.pth\n",
        "!pip install openai\n",
        "!pip install hpsv2\n",
        "!pip install diffusers"
      ],
      "metadata": {
        "id": "jkHXmku1sG6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adapter-transformers -U"
      ],
      "metadata": {
        "id": "cXtet_S_sJ0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de02e3a-7592-42c9-d48d-493e662a1cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adapter-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from adapter-transformers)\n",
            "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.35.2 requires tokenizers<0.19,>=0.14, but you have tokenizers 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/Shared drives/capstone_rlt2i/codes/reward_predictor/aesthetic_scores/')\n",
        "import simple_inference_custom"
      ],
      "metadata": {
        "id": "FVjIBLFusMBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import random\n",
        "# simple_inference_custom is the customized script we have to calcualte aesthetic score\n",
        "from simple_inference_custom import predict_aesthetic_score\n",
        "import torch\n",
        "import os\n",
        "import hpsv2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from base64 import b64decode"
      ],
      "metadata": {
        "id": "cxxGQLnMsP8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ct9OXEGYsSZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# policy model as an actor-critic model\n",
        "class PolicyModel(nn.Module):\n",
        "    def __init__(self, prompt_feature_size):\n",
        "        super(PolicyModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(prompt_feature_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "\n",
        "        # Actor layer for temperature\n",
        "        self.fc_actor_temp = nn.Linear(64, 1)\n",
        "\n",
        "        # Critic layer\n",
        "        self.fc_critic = nn.Linear(64, 1)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, prompt_features):\n",
        "        # Ensure prompt_features is a 2D tensor\n",
        "        if len(prompt_features.size()) == 1:\n",
        "            prompt_features = prompt_features.unsqueeze(0)\n",
        "        x = torch.relu(self.fc1(prompt_features))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "\n",
        "        # Actor output for temperature\n",
        "        temperature = self.sigmoid(self.fc_actor_temp(x))\n",
        "\n",
        "        # Critic output\n",
        "        # value_estimate = self.fc_critic(x)\n",
        "        # Added sigmoid activation to limit prediction value within 0 and 1\n",
        "        value_estimate = self.sigmoid(self.fc_critic(x))\n",
        "\n",
        "        return temperature, value_estimate\n",
        "\n",
        "    def initialize_with_defaults(self, default_temperature=0.9):\n",
        "        # For temperature: Using the sigmoid's inverse to get the pre-activation value\n",
        "        temp_bias = -torch.log(1. / torch.tensor(default_temperature) - 1.)\n",
        "        self.fc_actor_temp.bias.data.fill_(temp_bias.item())"
      ],
      "metadata": {
        "id": "KMc0z4Xvsc_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "EjNw_HchRwft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_path = '/content/drive/Shared drives/capstone_rlt2i/Momo/'\n",
        "training_data = pd.read_csv(training_data_path+'finetuning-dataset.csv')\n",
        "df_data_samples_evaluation = training_data[5000: 5300]"
      ],
      "metadata": {
        "id": "yz3fLi71tnbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data_samples_evaluation.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iLNVmkNpR0Go",
        "outputId": "11396786-6e5d-4f53-b27b-a7026a407144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Base_prompt  \\\n",
              "5000  of the dark jungle with large strange scary cr...   \n",
              "5001                                   portrait of apex   \n",
              "5002             hyperrealistic portrait of a cyberpunk   \n",
              "5003                       beautiful female ginger hair   \n",
              "5004                            2 8 mm closeup portrait   \n",
              "\n",
              "                                                 Prompt  \n",
              "5000  of the dark jungle with large strange scary cr...  \n",
              "5001  portrait of apex legends naomi campbell, intri...  \n",
              "5002  hyperrealistic portrait of a cyberpunk man, lo...  \n",
              "5003  beautiful female ginger hair glasses symmetric...  \n",
              "5004  2 8 mm closeup portrait of a beautiful bettie ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d5158de-17a4-4c52-ae7b-80e075a5e875\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Base_prompt</th>\n",
              "      <th>Prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5000</th>\n",
              "      <td>of the dark jungle with large strange scary cr...</td>\n",
              "      <td>of the dark jungle with large strange scary cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5001</th>\n",
              "      <td>portrait of apex</td>\n",
              "      <td>portrait of apex legends naomi campbell, intri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5002</th>\n",
              "      <td>hyperrealistic portrait of a cyberpunk</td>\n",
              "      <td>hyperrealistic portrait of a cyberpunk man, lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5003</th>\n",
              "      <td>beautiful female ginger hair</td>\n",
              "      <td>beautiful female ginger hair glasses symmetric...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5004</th>\n",
              "      <td>2 8 mm closeup portrait</td>\n",
              "      <td>2 8 mm closeup portrait of a beautiful bettie ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d5158de-17a4-4c52-ae7b-80e075a5e875')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d5158de-17a4-4c52-ae7b-80e075a5e875 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d5158de-17a4-4c52-ae7b-80e075a5e875');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8c10790f-5b14-43e3-ba29-f82447b6cdb7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c10790f-5b14-43e3-ba29-f82447b6cdb7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8c10790f-5b14-43e3-ba29-f82447b6cdb7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_PROMPT_FEATURE_SIZE = 768\n",
        "print(\"text feature size: \", YOUR_PROMPT_FEATURE_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zszdbg6PVqmh",
        "outputId": "13906bc6-1c3b-426d-873a-7fa0617a5a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text feature size:  768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iniatilization for temperatures, prompt length, and RL agent parameters\n",
        "DEFAULT_TEMPERATURE = 0.9\n",
        "EPSILON = 0.9\n",
        "EPSILON_DECAY = 0.995\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "loaded_policy_model = PolicyModel(prompt_feature_size=YOUR_PROMPT_FEATURE_SIZE)\n",
        "loaded_policy_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5WgKs6bVwTC",
        "outputId": "79eb3a24-6b4f-4fa6-866b-8ce2e7be2b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PolicyModel(\n",
              "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc_actor_temp): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (fc_critic): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model architecture\n",
        "# policy_model = PolicyModel(prompt_feature_size=YOUR_PROMPT_FEATURE_SIZE)\n",
        "\n",
        "# Load the state dictionary\n",
        "checkpoint_file_path = \"/content/drive/Shared drives/capstone_rlt2i/Momo/final_model/policy_model_checkpoint.pth\"\n",
        "checkpoint = torch.load(checkpoint_file_path)\n",
        "loaded_policy_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "loaded_policy_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMNYyHX9VzRj",
        "outputId": "cefdce04-ecae-4a47-8a12-4f5b8959bcb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PolicyModel(\n",
              "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc_actor_temp): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (fc_critic): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# function to extract text features\n",
        "def extract_bert_features(row):\n",
        "    text = row['Base_prompt']\n",
        "\n",
        "    # Load the BERT model and tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "    # Tokenize the text and truncate/pad it to the maximum length\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\").to(device)\n",
        "\n",
        "    # Extract text features\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        # You can use the pooled output or the last hidden states depending on your preference\n",
        "        text_features = outputs.pooler_output\n",
        "\n",
        "    return text_features.to('cpu')"
      ],
      "metadata": {
        "id": "kJkMCPgVXZGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "t2i_pipe = StableDiffusionPipeline.from_pretrained(\"prompthero/openjourney\", torch_dtype=torch.float32)\n",
        "t2i_pipe = t2i_pipe.to(device)"
      ],
      "metadata": {
        "id": "RoB7f6ZzXvdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text to image generation\n",
        "# use openjourney text to image model\n",
        "def text_to_image_generation(prompts):\n",
        "    images = t2i_pipe(prompts).images\n",
        "    return images"
      ],
      "metadata": {
        "id": "PYFm_72snaPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "access_token = \"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\"\n",
        "\n",
        "LM_tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token)\n",
        "LM_model = AutoModelForCausalLM.from_pretrained(model_name, token=access_token)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "LM_model.eval()"
      ],
      "metadata": {
        "id": "k6XUIuCDYm_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompts = (LM_tokenizer.bos_token + \"Base prompt: a green hair guy\\nEnriched prompt for text-to-image generation: a highly detailed portrait of a man with dark green hair and green glowing eyes, high detail clothing, concept art, anime, artstation, professional.\"+ LM_tokenizer.eos_token\n",
        "    + \"\\n\" + LM_tokenizer.bos_token + \"Base prompt: animal crossing werewolf\\nEnriched prompt for text-to-image generation: a cute chibi werewolf animal crossing villager. animal crossing character. 3 d render, 3 d model, simplified, animal crossing new horizons, hq, arstation.\"+ LM_tokenizer.eos_token\n",
        "    + \"\\n\" + LM_tokenizer.bos_token + \"Base prompt: an android woman\\nEnriched prompt for text-to-image generation: portrait of a beautiful android woman, futuristic, chrome and colorful, photo realistic, ray tracing, 3 d shading, octane render.\"+ LM_tokenizer.eos_token\n",
        ")\n",
        "\n",
        "few_shot_prompt_encoded = LM_tokenizer.encode(few_shot_prompts, return_tensors='pt')[0]"
      ],
      "metadata": {
        "id": "3bc8CEBkqASA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_enrichment(prompt, temperature=0.5, desired_length=300):\n",
        "    curr_prompt = \"Base prompt: \" + prompt + \"\\nEnriched prompt for text-to-image generation: \"\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    curr_prompt_encoded = LM_tokenizer.encode(\"\\n\" + LM_tokenizer.bos_token + curr_prompt, return_tensors='pt')[0]\n",
        "    input_ids = torch.cat((few_shot_prompt_encoded, curr_prompt_encoded), dim=0)\n",
        "\n",
        "    # Generate text with temperature and desired length\n",
        "    output = LM_model.generate(input_ids.unsqueeze(0), max_length=desired_length, num_return_sequences=1, bos_token_id=LM_tokenizer.bos_token_id,\n",
        "                            eos_token_id=LM_tokenizer.eos_token_id, temperature=temperature, do_sample=True)\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = LM_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Remove possible unwanted text\n",
        "    start_idx = generated_text.find(curr_prompt)\n",
        "    if start_idx != -1:\n",
        "        generated_text = generated_text[start_idx + len(curr_prompt):]\n",
        "\n",
        "    end_idx = generated_text.find(\"\\n\")\n",
        "    if end_idx != -1:\n",
        "        generated_text = generated_text[:end_idx]\n",
        "\n",
        "    end_idx = generated_text.find(\"Base prompt\")\n",
        "    if end_idx != -1:\n",
        "        generated_text = generated_text[:end_idx]\n",
        "\n",
        "    generated_text = generated_text.strip()\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "1GrYgOojvA3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to perform inference\n",
        "def perform_inference(initial_prompt):\n",
        "    # Extract text features from the initial prompt\n",
        "    text_features = extract_bert_features(initial_prompt).to(device)\n",
        "\n",
        "\n",
        "    # Predict the temperature using the loaded policy model\n",
        "    with torch.no_grad():\n",
        "        predicted_temperature, _ = loaded_policy_model(text_features)\n",
        "\n",
        "    # Use the predicted temperature for prompt enrichment\n",
        "    enriched_prompt = prompt_enrichment(initial_prompt, temperature=predicted_temperature.item())\n",
        "\n",
        "    # Perform text-to-image generation using the enriched prompt\n",
        "    generated_image = text_to_image_generation(enriched_prompt)\n",
        "\n",
        "    return enriched_prompt, generated_image, predicted_temperature.item()"
      ],
      "metadata": {
        "id": "0Smxgzr6s4pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "initial_prompt = \"A hungry cookie monster\"\n",
        "enriched_prompt, generated_image, predicted_temperature = perform_inference(initial_prompt)\n",
        "print(\"Enriched Prompt:\", enriched_prompt)\n",
        "print(\"Predicted Temperature:\", predicted_temperature)"
      ],
      "metadata": {
        "id": "e4BhkNoZvKqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# enriched all the evaluation prompts, generate images\n",
        "all_eval_prompts = df_data_samples_evaluation['Base_prompt']\n",
        "all_enriched_prompts = []\n",
        "all_predicted_temperatures = []\n",
        "all_generated_images = []\n",
        "for prompt in all_eval_prompts:\n",
        "    enriched_prompt, generated_image, predicted_temperature = perform_inference(initial_prompt)\n",
        "    all_enriched_prompts.append(enriched_prompt)\n",
        "    all_predicted_temperatures.append(predicted_temperature)\n",
        "    all_generated_images.append(generated_image)"
      ],
      "metadata": {
        "id": "GfQNZ4HSo8YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save enrichment results\n",
        "import pickle\n",
        "\n",
        "save_path = \"....\"\n",
        "# Save the generation results to a file\n",
        "with open(save_path + 'generation_results.pkl', 'wb') as file:\n",
        "    pickle.dump((all_enriched_prompts, all_predicted_temperatures, all_generated_images), file)"
      ],
      "metadata": {
        "id": "aQRQuMaAqdwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the generation results from the file\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/Shared drives/capstone_rlt2i/Momo/eval_results/generation_results_final.pkl', 'rb') as file:\n",
        "    loaded_results = pickle.load(file)\n",
        "\n",
        "# # You can access the loaded results like this:\n",
        "loaded_all_eval_prompts, loaded_all_enriched_prompts, loaded_all_predicted_temperatures, loaded_all_generated_images = loaded_results"
      ],
      "metadata": {
        "id": "bGVgj1EWgz-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_combined_score_new(text, image, w_aesthetic=0.5, w_hps=0.5):\n",
        "    try:\n",
        "        aesthetic_score = predict_aesthetic_score(image)\n",
        "        HPS_score = hpsv2.score(image, text)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    aesthetic_score_val = aesthetic_score.cpu().item()\n",
        "\n",
        "    # Normalize aesthetic score to be in the range [0, 1]\n",
        "    aesthetic_score_normalized = aesthetic_score_val / 10.0\n",
        "\n",
        "    # Apply power transformation to HPS score to amplify the difference between HPS scores\n",
        "    HPS_score_transformed = HPS_score[0]\n",
        "\n",
        "    # Since HPS score is already in the range [0, 1], we don't need to normalize it again\n",
        "    # Calculate the combined score as a weighted sum\n",
        "    combined_score = w_aesthetic * aesthetic_score_normalized + w_hps * HPS_score_transformed\n",
        "\n",
        "    # Convert to PyTorch tensor\n",
        "    combined_score_tensor = torch.tensor(combined_score, requires_grad=False).to(device)\n",
        "\n",
        "    return combined_score_tensor"
      ],
      "metadata": {
        "id": "xPbNwlyXqc-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wour_scores = [compute_combined_score_new(text, image[0]) for text, image in zip(loaded_all_enriched_prompts, loaded_all_generated_images)]"
      ],
      "metadata": {
        "id": "X_6TjvRfqgWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "02651f20f29047b78d3b386322295ff1",
            "49802b163e74474c89dd9d1df08a4347",
            "709769c8c13b4a0d8732566661fbbe31",
            "e0d37eba4c4447cdb7b94adafe08746b",
            "9cdde9d9c208478daa47ed660f487416",
            "94017d5ff0ae42ebb610b63d70522698",
            "cd726dcba31948c891cfcf4bb362318d",
            "9640fe5678864b5ab8cf5798cecd1abd",
            "8ee0456a4f064d01a8cc7b4ecf553375",
            "f650e84f22a144cea907a34152498273",
            "4613cef43fe84a4ab1d36e9b6cfa8678"
          ]
        },
        "outputId": "79bc38f5-a8b9-4e9c-c2b6-4463730b229d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0886]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "open_clip_pytorch_model.bin:   0%|          | 0.00/3.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02651f20f29047b78d3b386322295ff1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading HPS_v2_compressed.pt ...\n",
            "Download HPS_2_compressed.pt to /root/.cache/hpsv2/ sucessfully.\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6891]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5518]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7331]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.4302]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6488]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5084]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7119]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4356]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.1865]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1811]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.8947]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9832]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3150]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7793]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9811]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0056]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1014]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8684]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6979]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4077]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9173]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3442]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.4858]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0352]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0709]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0474]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3260]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5069]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6084]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.6139]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.1899]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7477]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6094]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7228]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6318]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0070]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7399]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2543]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9538]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7907]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.5528]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0486]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1642]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0125]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.3897]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.2473]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3477]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0495]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5197]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0520]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.6021]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3338]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6871]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7329]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7097]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2178]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6803]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8836]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3864]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6235]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9281]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3948]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8583]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.6956]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3945]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8907]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9136]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9093]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3320]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0304]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2059]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7986]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3475]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3042]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3573]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2126]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8505]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5247]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8010]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.6004]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5847]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4817]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.5701]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0189]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0958]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1707]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6228]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1187]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7858]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4759]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3856]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6844]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9204]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9721]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8828]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7836]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6266]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2602]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5530]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.6018]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2915]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6453]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8340]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5335]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.3831]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4936]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6928]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0094]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5929]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2404]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.2599]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5916]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5620]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.8750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6931]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1954]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7874]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0923]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7423]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0165]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.1362]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0292]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.5087]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0069]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1703]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7014]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9221]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5236]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4930]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9533]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5631]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6196]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4261]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.2926]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9417]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3418]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1946]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2446]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6777]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3290]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3052]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2910]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8806]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3869]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2959]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1391]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4646]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4253]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0170]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7101]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3638]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2666]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0670]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0042]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7507]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9370]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7197]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9779]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0425]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.8684]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9986]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.2086]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[4.9358]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.8687]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.1397]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9209]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.8435]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.2119]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4780]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7912]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0949]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3361]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7860]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9583]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0526]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1553]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1212]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5364]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7024]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0467]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3219]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1814]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0411]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.6298]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4023]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3755]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9971]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.1737]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3464]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5809]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6271]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.1702]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0153]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7020]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4017]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2266]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0091]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2396]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2908]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5106]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5527]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.2337]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9598]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0556]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6827]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5957]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3522]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0450]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.1167]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5163]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5966]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7398]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7880]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0793]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7307]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1242]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5896]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.8850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2442]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2802]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.4072]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3633]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0737]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2821]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9002]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5532]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.2285]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7988]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7222]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8969]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5286]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7704]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8165]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[3.6657]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.4627]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8505]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.2743]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9733]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3863]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9864]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.8712]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2561]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5248]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.8958]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3824]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5592]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0578]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.5894]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9426]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.0512]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1517]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8057]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0332]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.8081]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9321]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.1872]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3623]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3284]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.5558]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4537]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3829]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.7707]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7370]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.9543]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6246]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.1049]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1078]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7411]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3454]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4933]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3993]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7169]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7848]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7042]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5499]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2690]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3716]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5676]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.6648]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6202]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5692]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.9112]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7191]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.2229]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.6862]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.7624]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.3675]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5650]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.7387]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1868]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.4938]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[7.0726]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.4521]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.1729]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[5.8964]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "Aesthetic score predicted by the model:\n",
            "tensor([[6.5146]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_enriched_prompts = df_data_samples_evaluation['Prompt']\n",
        "reference_images = [text_to_image_generation(reference_prompt) for reference_prompt in reference_enriched_prompts]"
      ],
      "metadata": {
        "id": "KYcskKULwWu8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "43025327-bd4e-484b-afb4-b6b45bf12e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-01806beca595>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreference_enriched_prompts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data_samples_evaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Prompt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreference_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext_to_image_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreference_prompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreference_enriched_prompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_data_samples_evaluation' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reference_scores = [compute_combined_score_new(text, image) for text, image in zip(reference_enriched_prompts, reference_images)]"
      ],
      "metadata": {
        "id": "POnQppq8rqG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot our enriched scores vs. reference enriched scores"
      ],
      "metadata": {
        "id": "WfZHCwgfw3l4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_score_distribution(scores, label_text, color_code):\n",
        "    # Plotting the new scores distribution with rounded scores\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(scores, bins=20, alpha=0.7, color= color_code, label=label_text)\n",
        "    plt.xlabel('Combined Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Combined Scores - ', label_text)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_kGQmF2Pw8Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pastel Purple: #B19CD9\n",
        "# Pastel Yellow: #FFFF99\n",
        "# Pastel Pink: #FFD1DC"
      ],
      "metadata": {
        "id": "J2UgPiVHyZwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_score_distribution(our_scores, 'RL guided enriched prompts',  '#B19CD9')"
      ],
      "metadata": {
        "id": "dRizSGv2xWte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_score_distribution(our_scores, 'Reference enriched prompts', '#FFFF99')"
      ],
      "metadata": {
        "id": "IKB42xddxikB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot temperature distribution in generation"
      ],
      "metadata": {
        "id": "czpqM6Vpxx5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_temperature_distribution(temperatures, label_text, color_code):\n",
        "    # Plotting the new scores distribution with rounded scores\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(scores, bins=20, alpha=0.7, color= color_code, label=label_text)\n",
        "    plt.xlabel('Combined Score')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Combined Scores - ', label_text)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EU6Md2GTx0yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_temperature_distribution(all_predicted_temperatures, 'predicted temperature distribution', '#FFD1DC')"
      ],
      "metadata": {
        "id": "Q_ie14D9x7M2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}